{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Linear Algebra] Final Assignment \n",
    "# Solve Least Squre Problem using normal equation\n",
    "## 의용생체공학과 201838205 김나연\n",
    "------------------------------------------------------\n",
    "## < Contents >\n",
    "### 1. Overdetermined\n",
    "### 2. Orthogonal Projection\n",
    "### 3. Least Square Method\n",
    "### 4. Example in Machine Learning\n",
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overdetermined \n",
    "### 1. 1 Overdetermined란\n",
    "> ### *Def*\n",
    "> * **unknown < equation**인 경우이다. \n",
    "> * m x n matrix의 경우, m>n인 matrix를 overdetermined matrix라고 칭한다. \n",
    "> * rank는 m보다 작고 최소 n이다. \n",
    "> * 참고로 **unknown > equation**은 undetermined, **unknown = equation**은 determined라고 칭한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Overdetermined의 해(solution)\n",
    "* overdetermined는 일반적으로 inconsistent하다.(해가 없다.)\n",
    "> * *예시*  \n",
    "> $A\\mathbf{x}=\\mathbf{b}\\sim$ $\\begin{bmatrix} 1 & 1 & 2 \\\\ 3 & 4 & 1 \\\\ 3 & 7 & 1 \\\\ 4 & 2 & 3 \\end{bmatrix} $ $\\begin{bmatrix} x_{1} \\\\  x_{2} \\\\  x_{3} \\end{bmatrix} = $ $\\begin{bmatrix} 11 \\\\  2 \\\\  -7 \\\\ 21  \\end{bmatrix}\\cdots (1)$  \n",
    "$\\begin{bmatrix} A   \\mathbf{b} \\end{bmatrix}= \\begin{bmatrix} 1 & 1 & 2 & 11 \\\\ 3 & 4 & 1 & 2 \\\\ 3 & 7 & 1 & -7 \\\\ 4 & 2 & 3 & 21 \\end{bmatrix} \\sim \\begin{bmatrix} 1 & 1 & 2 & 11 \\\\ 0 & 1 & -5 & 29 \\\\ 0 & 0 & 25 & 7 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} \\cdots (2)$  \n",
    "> $\\therefore$ 식 (2)의 row 4와 같이 성립되지 않는 식이 발생한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 best solution(최적해) 구하기\n",
    "* overdetermined의 해를 구해보자 !\n",
    "* 아니 아까는 해가 없다고 하지 않았는가. 해가 없는데 해를 구한다니..\n",
    "* 해가 없어도 우리는 해를 구하고 싶다! 그러니깐 해를 구해보자.\n",
    "* 어떻게?\n",
    "> **정확한 해가 아닌 가장 근사한 해(best solution)를 구하면 어떨까?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 $A^TA$ (A is m * n matrix, m > n) $\\cdots(3)$\n",
    "* 일단 해를 구하기 위해서 $A$를 **Invertible matrix Theorem**에 성립하도록 만들어 줄 것이다. \n",
    "    * square matrix로 만들기 \n",
    "    > * matrix $A$ 앞에 $A^T$를 곱해보자\n",
    "    > * (nxm)(mxn) = (nxn)\n",
    "    * Symmetric matrix (대칭행렬)\n",
    "    > Symmetric matrix는 Transpose 후에도 원래의 자기 자신과 똑같다.\n",
    "    > orthonormal matrix와 eigen value, orthonormal matrix의 Transpose들의 곱으로 분해해서 표현 가능\n",
    "    >  $(A^TA)^T = A^TA^TT = A^TA$ \n",
    "    * full rank (== free variable 없음. == $A$의 $columns$이 linearly independent)\n",
    "    > * $A^TA\\mathbf{\\hat{x}} = A^T\\mathbf{b}\\cdots (4)$\n",
    "    > * $(A^TA)^-1A^TA\\mathbf{\\hat{x}} = (A^TA)^-1A^T\\mathbf{b}\\cdots (5)$\n",
    "    > * $I\\mathbf{\\hat{x}} = (A^TA)^-1A^T\\mathbf{b}\\cdots (6)$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 예시\n",
    "* $A\\mathbf{x}=\\mathbf{b}\\sim$ $\\begin{bmatrix} 1 & 1 & 2 \\\\ 3 & 4 & 1 \\\\ 3 & 7 & 1 \\\\ 4 & 2 & 3 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\  x_{2} \\\\  x_{3} \\end{bmatrix} = \\begin{bmatrix} 11 \\\\  2 \\\\  -7 \\\\ 21  \\end{bmatrix} \\cdots (1)$  \n",
    "* $A^TA\\mathbf{\\hat{x}} = A^T\\mathbf{b} \\rightarrow \\begin{bmatrix} 1 & 3 & 3 & 4 \\\\ 1 & 4 & 7 & 2 \\\\ 2 & 1 & 1 & 3 \\end{bmatrix} \\begin{bmatrix} 1 & 1 & 2 \\\\ 3 & 4 & 1 \\\\ 3 & 7 & 1 \\\\ 4 & 2 & 3 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\  x_{2} \\\\  x_{3} \\end{bmatrix} = \\begin{bmatrix} 1 & 3 & 3 & 4 \\\\ 1 & 4 & 7 & 2 \\\\ 2 & 1 & 1 & 3 \\end{bmatrix} \\begin{bmatrix} 11 \\\\  2 \\\\  -7 \\\\ 21  \\end{bmatrix} ~ \\begin{bmatrix} 35 & 42 & 20 \\\\ 42 & 70 & 19 \\\\ 20 & 19 & 15 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\  x_{2} \\\\  x_{3} \\end{bmatrix} = \\begin{bmatrix} 80 \\\\ 12 \\\\ 80 \\end{bmatrix}$\n",
    "* $(A^TA)^-1A^TA\\mathbf{\\hat{x}} = (A^TA)^-1A^T\\mathbf{b} \\sim \\mathbf{\\hat{x}} = (A^TA)^-1A^T\\mathbf{b} \\rightarrow \\begin{bmatrix} 0.43 & -0.15 & -0.38 \\\\ -0.15 & 0.07 & 0.11 \\\\ -0.38 & 0.11 & 0.43 \\end{bmatrix} \\begin{bmatrix} 35 & 42 & 20 \\\\ 42 & 70 & 19 \\\\ 20 & 19 & 15 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\  x_{2} \\\\  x_{3} \\end{bmatrix} = \\begin{bmatrix} 0.43 & -0.15 & -0.38 \\\\ -0.15 & 0.07 & 0.11 \\\\ -0.38 & 0.11 & 0.43 \\end{bmatrix}\\begin{bmatrix} 80 \\\\ 12 \\\\ 80 \\end{bmatrix} \\sim \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\  x_{2} \\\\  x_{3} \\end{bmatrix} = \\begin{bmatrix} 2.51 \\\\ -2.85 \\\\ 5.6 \\end{bmatrix}$\n",
    "* $A\\mathbf{hat{x}}=\\mathbf{b} \\rightarrow \\begin{bmatrix} 1 & 1 & 2 \\\\ 3 & 4 & 1 \\\\ 3 & 7 & 1 \\\\ 4 & 2 & 3 \\end{bmatrix} \\begin{bmatrix} 2.51 \\\\  -2.85 \\\\  5.6 \\end{bmatrix} = \\begin{bmatrix} 10.85 \\\\ 1.71 \\\\ -6.85 \\\\ 21.14 \\end{bmatrix}$\n",
    "* $\\therefore$ 원래 $\\mathbf{b}=\\begin{bmatrix} 11 \\\\  2 \\\\  -7 \\\\ 21  \\end{bmatrix}$ 값과 비교했을 때 근사한 값으로 구한 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "## 2. Orthogonal Projection\n",
    "### 2.1 vector projection \n",
    "* 두 개의 벡터 중 하나의 벡터를 다른 하나의 벡터에 projection시키는 것\n",
    "> vector a에 vector b를 projection\n",
    "![nn](./img/vector_projection.png)\n",
    "> * $\\mathbf{p}$ : $\\mathbf{a}$에 $\\mathbf{b}$를 projection한 결과 \n",
    "> * $\\mathbf{e}$ : projection 전후 차이, 즉 error, **$\\mathbf{a}$와 orthogonal 관계 $\\rightarrow \\mathbf{a}^T\\mathbf{e}=0 \\rightarrow \\mathbf{a}^T(\\mathbf{b}-\\mathbf{p})=0 \\rightarrow \\mathbf{a}^T(\\mathbf{b}-x\\mathbf{a})=0$**\n",
    "> * $x\\mathbf{a}^T\\mathbf{b}-x\\mathbf{a}^T\\mathbf{a}=0$\n",
    "> * $x\\mathbf{a}^T\\mathbf{a}=\\mathbf{a}^T\\mathbf{b}$\n",
    "> * $x = \\mathbf{a}^T\\mathbf{b}/\\mathbf{a}^T\\mathbf{a}$$\\cdots(7)$\n",
    "> * $\\mathbf{p}=\\mathbf{a}(\\mathbf{a}^T\\mathbf{b}/\\mathbf{a}^T\\mathbf{a})$$\\cdots(8)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 projection을 하는 이유\n",
    "* Overdetermined의 경우 $A\\mathbf{x}=\\mathbf{b}$에서 $A\\mathbf{x}$의 결과 벡터는 항상 $A$에 존재\n",
    "* 하지만, $\\mathbf{b}$는 $A$의 column space에 존재하지 않음.\n",
    "* $A\\mathbf{x}=\\mathbf{b}$, 양변의 불일치\n",
    "> 불일치를 수정하려면?\n",
    "> * 후보1, $A$: 이미 정해진 시스템 변경 불가\n",
    "> * 후보2, $\\mathbf{x}$: unknown\n",
    "> * 후보3, $\\mathbf{b}$: **$A$의 column space에서 가장 비슷한 벡터로 수정하자**\n",
    "    * $A$의 column space로 projection한 벡터 $\\mathbf{p}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 normal equation\n",
    "* overdetermined $A\\mathbf{x}=\\mathbf{b}$에서 best solution $A\\mathbf{\\hat{x}}=\\mathbf{b}$를 구할 때, ($A=\\begin{bmatrix} \\mathbf{a}_1 & \\mathbf{a}_2 \\end{bmatrix} $)\n",
    "* $\\mathbf{p}=A\\mathbf{\\hat{x}}$, $\\mathbf{b}-\\mathbf{p} \\rightarrow \\mathbf{b}-A\\mathbf{\\hat{x}}\\perp plane$\n",
    "* $\\mathbf{a}_1^T(\\mathbf{b}-A\\mathbf{\\hat{x}}) = 0, \\mathbf{a}_2^T(\\mathbf{b}-A\\mathbf{\\hat{x}}) = 0$\n",
    "* $\\begin{bmatrix} \\mathbf{a}_1^T \\\\ \\mathbf{a}_2^T  \\end{bmatrix} (\\mathbf{b}-A\\mathbf{\\hat{x}}) = \\begin{bmatrix} 0 \\\\ 0  \\end{bmatrix}$ \n",
    "* $A^T(\\mathbf{b}-A\\mathbf{\\hat{x}} = 0$\n",
    "* $A^TA\\mathbf{\\hat{x}} = A^T\\mathbf{b}$ \n",
    "* $\\mathbf{\\hat{x}} = (A^TA)^-1A^T\\mathbf{b} \\cdots(9)$ (;normal equation)\n",
    "* $\\mathbf{p}=A\\mathbf{\\hat{x}} = A(A^TA)^-1A^T\\mathbf{b}$\n",
    "* $P = A(A^TA)^-1A^T (\\mathbf{p}=P\\mathbf{b}) \\cdots(10)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "## 3. Least Square Problem(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Least Square Problem 등장 배경\n",
    "* 만약 여러 조건을 고려하여 상품의 가격을 결정하는 식을 생각해보자. \n",
    "* 수익율을 예측하기 위해 수요도, 가격, 홍보정도 등 10개의 조건을 제시하고 그에 대한 방정식을 수백개를 얻었다고 하자. \n",
    "* 그러면 unknown은 10개, equation은 수백개인 overdetermined 상태다.\n",
    "* 아까 위에서 overdetermined는 inconsistent, 즉 solution이 없다며 !! 에이 그럼 못 풀겠네 !! \n",
    "* 사실 이 문제를 가장 간단히 해결하기 위한 방법이 있다. unknown의 개수만큼만 equation을 남겨 n x n matrix(;determined)로 만드는 것이다.\n",
    "* 그런데 과연 이게 올바른 방법일까?? $\\rightarrow$ 아니라고 생각한다. 왜냐하면 남겨놓을 equation을 어떤 기준으로 선정할 것인지 모호하기 때문이다.또한 데이터가 적어질수록 유사도가 떨어진다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 2 Least Square란\n",
    "* 데이터셋을 가장 잘 표현할 수 있는 예측 line을 결정하는 수학적 모델이다.\n",
    "* 주어진 모든 데이터에 대해 **예측값과 실제 데이터 값 사이의 에러의 제곱의 합을 최소화**하는 파라미터를 찾는 방법\n",
    "* Regression과 같은 개념\n",
    "* 실제 데이터와 예측값 간에 차이를 시각적으로 표현이나 시스템 특성 파악에도 유용하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 3 Solution\n",
    "* $Minimize \\parallel A\\mathbf{x} - \\mathbf{b}\\parallel^2 = \\parallel\\mathbf{e}\\parallel^2$\n",
    "* 예시\n",
    "> ![nn](./img/LS_example.png)\n",
    "> * $A\\mathbf{x} = \\mathbf{b} \\rightarrow \\begin{bmatrix} 1 & 1  \\\\ 2 & 1  \\\\ 3 & 1 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\  x_{2} \\end{bmatrix} = \\begin{bmatrix} 1 \\\\  2 \\\\  2 \\end{bmatrix} $\n",
    "> * 위의 그림을 보면 알 수 있듯이 세 개의 좌표를 모두 통과하는 직선은 존재하지 않는다. 즉, 완벽한 해가 존재하지 않는다\n",
    "> 각각 좌표와 직선 간 에러의 제곱들의 총합이 최소가 되도록 하는 선을 찾는 것이 목표\n",
    "> * $A\\mathbf{\\hat{x}} = \\mathbf{p} \\rightarrow \\begin{bmatrix} 1 & 1  \\\\ 2 & 1  \\\\ 3 & 1 \\end{bmatrix} \\begin{bmatrix} \\hat{x_{1}} \\\\  \\hat{x_{2}} \\end{bmatrix} = \\begin{bmatrix} p_{1} \\\\  p_{2} \\\\  p_{3} \\end{bmatrix} $\n",
    "> * $A^TA\\mathbf{\\hat{x}} = A^T\\mathbf{b} \\rightarrow \\begin{bmatrix} 1 & 2 & 3 \\\\ 1 & 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 1 \\\\ 2 & 1 \\\\ 3 & 1 \\\\ \\end{bmatrix} \\begin{bmatrix} \\hat{x_{1}} \\\\  \\hat{x_{2}} \\end{bmatrix} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 1 & 1 & 1 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 \\\\  2 \\\\  2 \\end{bmatrix} \\sim \\begin{bmatrix} 14 & 6 \\\\ 6 & 3 \\end{bmatrix} \\begin{bmatrix} \\hat{x_{1}} \\\\  \\hat{x_{2}} \\end{bmatrix} = \\begin{bmatrix} 11 \\\\ 5 \\end{bmatrix} $\n",
    "> * $\\begin{bmatrix} 14 \\\\ 6 \\end{bmatrix}\\hat{x_{1}} + \\begin{bmatrix} 6 \\\\ 3 \\end{bmatrix}\\hat{x_{2}} = \\begin{bmatrix} 11 \\\\ 5 \\end{bmatrix}$    \n",
    "> * $\\hat{x_{1}} = 1/2, \\hat{x_{2}} = 2/3$\n",
    "> * $\\therefore$ $p = 1/2t + 2/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 기하학적 의미\n",
    "* $\\mathbf{e}$가 orthogonal한 것은 $p$ 뿐만이 아니라 $p$가 존재하는 column space 전체와 orthogonal하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example in Machine Learning\n",
    "### 주택 평 수(크기)와 거주자 수에 따른 주택 가격 예측 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $A=\\begin{bmatrix} \\mathbf{a}_1 & \\mathbf{a}_2 \\end{bmatrix}$, $\\mathbf{a}_1$ : 주택 평 수 데이터 값, $\\mathbf{a}_2$ : 거주자 수 데이터 값 \n",
    "* 주택 가격의 단위는 억\n",
    "* $\\mathbf{\\hat{x_{1}}}$: 평 수 예측 값 , $\\mathbf{\\hat{x_{2}}}$: 거주자 수 예측 값 \n",
    "* $ \\begin{bmatrix} 30 & 4  \\\\ 20 & 3  \\\\ 27 & 3 \\\\ 40 & 5 \\end{bmatrix} \\begin{bmatrix} x_{1} \\\\  x_{2} \\end{bmatrix} = \\begin{bmatrix} 4 \\\\  2.5 \\\\  3 \\\\ 8 \\end{bmatrix} $\n",
    "* $ \\begin{bmatrix} 30 & 20 & 27 & 40 \\\\ 4 & 3 & 3 & 5 \\end{bmatrix} \\begin{bmatrix} 30 & 4  \\\\ 20 & 3  \\\\ 27 & 3 \\\\ 40 & 5 \\end{bmatrix} \\begin{bmatrix} \\hat{x_{1}} \\\\  \\hat{x_{2}} \\end{bmatrix} =  \\begin{bmatrix} 30 & 20 & 27 & 40 \\\\ 4 & 3 & 3 & 5 \\end{bmatrix}\\begin{bmatrix} 4 \\\\  2.5 \\\\  3 \\\\ 8 \\end{bmatrix} \\sim \\begin{bmatrix} 3629 & 461 \\\\ 461 & 59 \\end{bmatrix} \\begin{bmatrix} \\hat{x_{1}} \\\\  \\hat{x_{2}} \\end{bmatrix} = \\begin{bmatrix} 571 \\\\ 72.5 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Reference\n",
    "    * 블로그 Learn Again! https://twlab.tistory.com/35?category=668741\n",
    "    * 블로그 다크프로그래머 https://darkpgmr.tistory.com/105?category=460967\n",
    "    * 강의 인공지능을 위한 선형대수\n",
    "    * 위키피디아"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
